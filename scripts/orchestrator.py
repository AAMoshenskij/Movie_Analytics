#!/usr/bin/env python3
"""
–ü—Ä–æ—Å—Ç–æ–π –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è ETL –ø–∞–π–ø–ª–∞–π–Ω–æ–º
–ó–∞–º–µ–Ω–∏—Ç–µ–ª—å Airflow –¥–ª—è –Ω–∞—à–µ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞
"""
import schedule
import time
import subprocess
import threading
from datetime import datetime
import psycopg2
import json

class MovieAnalyticsOrchestrator:
    def __init__(self):
        self.spark_process = None
        self.is_running = False
        
    def start_spark_streaming(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç Spark Streaming –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ"""
        if self.spark_process and self.spark_process.poll() is None:
            print("‚ö†Ô∏è Spark Streaming —É–∂–µ –∑–∞–ø—É—â–µ–Ω")
            return
            
        print("üöÄ –ó–∞–ø—É—Å–∫ Spark Streaming...")
        self.spark_process = subprocess.Popen([
            'python3', 'scripts/spark_streaming_postgres_robust.py'
        ])
        
    def stop_spark_streaming(self):
        """–û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç Spark Streaming"""
        if self.spark_process:
            print("üõë –û—Å—Ç–∞–Ω–æ–≤–∫–∞ Spark Streaming...")
            self.spark_process.terminate()
            self.spark_process.wait()
            print("‚úÖ Spark Streaming –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
            
    def generate_test_data(self):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ"""
        print("üé≤ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
        try:
            result = subprocess.run([
                'python3', 'scripts/kafka_producer_fixed.py'
            ], capture_output=True, text=True, timeout=120)
            
            if result.returncode == 0:
                print("‚úÖ –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã")
            else:
                print(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {result.stderr}")
                
        except subprocess.TimeoutExpired:
            print("‚è∞ –¢–∞–π–º–∞—É—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
            
    def run_etl_pipeline(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–ª–Ω—ã–π ETL –ø–∞–π–ø–ª–∞–π–Ω"""
        print(f"üîß [{datetime.now()}] –ó–∞–ø—É—Å–∫ ETL –ø–∞–π–ø–ª–∞–π–Ω–∞...")
        
        try:
            # 1. –ó–∞–ø—É—Å–∫–∞–µ–º Spark Streaming
            self.start_spark_streaming()
            time.sleep(10)  # –ñ–¥–µ–º –∑–∞–ø—É—Å–∫–∞
            
            # 2. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
            self.generate_test_data()
            
            # 3. –ñ–¥–µ–º –æ–±—Ä–∞–±–æ—Ç–∫–∏
            time.sleep(30)
            
            # 4. –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            self.check_data_quality()
            
            print(f"‚úÖ [{datetime.now()}] ETL –ø–∞–π–ø–ª–∞–π–Ω –∑–∞–≤–µ—Ä—à–µ–Ω")
            
        except Exception as e:
            print(f"‚ùå [{datetime.now()}] –û—à–∏–±–∫–∞ ETL: {e}")
            
    def check_data_quality(self):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö"""
        print("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö...")
        
        try:
            conn = psycopg2.connect(
                host="localhost", port=5432,
                database="analytics", user="admin", password="password"
            )
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π
            cur = conn.cursor()
            cur.execute("SELECT COUNT(*) FROM user_views_processed")
            count = cur.fetchone()[0]
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –∑–∞–ø–∏—Å–∏
            cur.execute("""
                SELECT COUNT(*), AVG(duration_seconds), COUNT(DISTINCT user_id)
                FROM user_views_processed 
                WHERE processing_timestamp >= NOW() - INTERVAL '1 hour'
            """)
            stats = cur.fetchone()
            
            print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–∞–Ω–Ω—ã—Ö:")
            print(f"   - –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {count}")
            print(f"   - –ó–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–∞—Å: {stats[0]}")
            print(f"   - –°—Ä–µ–¥–Ω—è—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {stats[1]:.2f} —Å–µ–∫")
            print(f"   - –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏: {stats[2]}")
            
            conn.close()
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
            
    def generate_daily_report(self):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –µ–∂–µ–¥–Ω–µ–≤–Ω—ã–π –æ—Ç—á–µ—Ç"""
        print(f"üìà [{datetime.now()}] –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –µ–∂–µ–¥–Ω–µ–≤–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞...")
        
        try:
            conn = psycopg2.connect(
                host="localhost", port=5432,
                database="analytics", user="admin", password="password"
            )
            
            # –û—Ç—á–µ—Ç –ø–æ –ø–æ–ø—É–ª—è—Ä–Ω—ã–º —Ñ–∏–ª—å–º–∞–º
            cur = conn.cursor()
            cur.execute("""
                SELECT 
                    movie_id,
                    COUNT(*) as view_count,
                    AVG(duration_seconds) as avg_duration,
                    COUNT(DISTINCT user_id) as unique_users
                FROM user_views_processed 
                WHERE processing_timestamp >= CURRENT_DATE - INTERVAL '1 day'
                GROUP BY movie_id
                ORDER BY view_count DESC
                LIMIT 10
            """)
            
            popular_movies = cur.fetchall()
            
            print("üé¨ –¢–æ–ø-10 –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö —Ñ–∏–ª—å–º–æ–≤ –∑–∞ –¥–µ–Ω—å:")
            for i, (movie_id, views, avg_dur, unique_users) in enumerate(popular_movies, 1):
                print(f"   {i}. {movie_id}: {views} –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤, {avg_dur:.1f} —Å–µ–∫ –≤ —Å—Ä–µ–¥–Ω–µ–º, {unique_users} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç –≤ —Ñ–∞–π–ª
            report = {
                "generated_at": datetime.now().isoformat(),
                "popular_movies": [
                    {"movie_id": m[0], "views": m[1], "avg_duration": m[2], "unique_users": m[3]}
                    for m in popular_movies
                ]
            }
            
            with open('reports/daily_report.json', 'w') as f:
                json.dump(report, f, indent=2)
                
            print("‚úÖ –ï–∂–µ–¥–Ω–µ–≤–Ω—ã–π –æ—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ reports/daily_report.json")
            
            conn.close()
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç—á–µ—Ç–∞: {e}")
            
    def health_check(self):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∑–¥–æ—Ä–æ–≤—å–µ —Å–∏—Å—Ç–µ–º—ã"""
        print(f"‚ù§Ô∏è  [{datetime.now()}] –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è —Å–∏—Å—Ç–µ–º—ã...")
        
        services_ok = 0
        total_services = 3
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º PostgreSQL
        try:
            conn = psycopg2.connect(
                host="localhost", port=5432,
                database="analytics", user="admin", password="password"
            )
            conn.close()
            print("   ‚úÖ PostgreSQL: OK")
            services_ok += 1
        except:
            print("   ‚ùå PostgreSQL: ERROR")
            
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º Kafka (—É–ø—Ä–æ—â–µ–Ω–Ω–æ)
        try:
            import socket
            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            sock.settimeout(2)
            result = sock.connect_ex(('localhost', 9092))
            sock.close()
            if result == 0:
                print("   ‚úÖ Kafka: OK")
                services_ok += 1
            else:
                print("   ‚ùå Kafka: ERROR")
        except:
            print("   ‚ùå Kafka: ERROR")
            
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º Spark (—É–ø—Ä–æ—â–µ–Ω–Ω–æ)
        try:
            import requests
            response = requests.get("http://localhost:8080", timeout=5)
            if response.status_code == 200:
                print("   ‚úÖ Spark: OK")
                services_ok += 1
            else:
                print("   ‚ùå Spark: ERROR")
        except:
            print("   ‚ùå Spark: ERROR")
            
        print(f"   üìä –°—Ç–∞—Ç—É—Å: {services_ok}/{total_services} —Å–µ—Ä–≤–∏—Å–æ–≤ —Ä–∞–±–æ—Ç–∞—é—Ç")
        
    def start(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä"""
        print("üéØ –ó–∞–ø—É—Å–∫ –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–∞ Movie Analytics...")
        print("=" * 50)
        
        # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è –æ—Ç—á–µ—Ç–æ–≤
        subprocess.run(['mkdir', '-p', 'reports'])
        
        # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ
        schedule.every(2).hours.do(self.run_etl_pipeline)
        schedule.every().day.at("23:00").do(self.generate_daily_report)
        schedule.every(30).minutes.do(self.health_check)
        
        print("üìÖ –†–∞—Å–ø–∏—Å–∞–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–æ:")
        print("   - ETL –ø–∞–π–ø–ª–∞–π–Ω: –∫–∞–∂–¥—ã–µ 2 —á–∞—Å–∞")
        print("   - –ï–∂–µ–¥–Ω–µ–≤–Ω—ã–π –æ—Ç—á–µ—Ç: –∫–∞–∂–¥—ã–π –¥–µ–Ω—å –≤ 23:00")
        print("   - –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è: –∫–∞–∂–¥—ã–µ 30 –º–∏–Ω—É—Ç")
        print("=" * 50)
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–µ—Ä–≤—É—é –ø—Ä–æ–≤–µ—Ä–∫—É
        self.health_check()
        
        self.is_running = True
        try:
            while self.is_running:
                schedule.run_pending()
                time.sleep(60)
        except KeyboardInterrupt:
            print("\nüõë –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–∞...")
            self.stop_spark_streaming()
            
    def stop(self):
        """–û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä"""
        self.is_running = False
        self.stop_spark_streaming()

if __name__ == "__main__":
    orchestrator = MovieAnalyticsOrchestrator()
    orchestrator.start()