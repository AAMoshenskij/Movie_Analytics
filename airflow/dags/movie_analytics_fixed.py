from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.operators.bash import BashOperator
from airflow.providers.postgres.hooks.postgres import PostgresHook
from datetime import datetime, timedelta

default_args = {
    'owner': 'data_engineer',
    'depends_on_past': False,
    'start_date': datetime(2024, 1, 1),
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 1,
    'retry_delay': timedelta(minutes=5)
}

def check_database_connection():
    """ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÑ‚ Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ Ðº Ð±Ð°Ð·Ðµ Ð´Ð°Ð½Ð½Ñ‹Ñ…"""
    print("ðŸ” ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ñ Ðº Ð±Ð°Ð·Ðµ Ð´Ð°Ð½Ð½Ñ‹Ñ…...")
    try:
        hook = PostgresHook(postgres_conn_id='analytics_db')
        conn = hook.get_conn()
        cursor = conn.cursor()
        
        # ÐŸÑ€Ð¾ÑÑ‚Ð¾Ð¹ Ð·Ð°Ð¿Ñ€Ð¾Ñ Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ¸
        cursor.execute("SELECT 1")
        result = cursor.fetchone()
        
        print(f"âœ… ÐŸÐ¾Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾: {result}")
        
        # ÐŸÑ€Ð¾Ð²ÐµÑ€Ð¸Ð¼ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñ‹
        cursor.execute("""
            SELECT table_name 
            FROM information_schema.tables 
            WHERE table_schema = 'public'
            ORDER BY table_name
        """)
        tables = cursor.fetchall()
        
        print("ðŸ“Š Ð”Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ‹Ðµ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñ‹:")
        for table in tables:
            print(f"   - {table[0]}")
            
        cursor.close()
        conn.close()
        
    except Exception as e:
        print(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ñ: {e}")
        raise

def generate_test_data():
    """Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÑ‚ Ñ‚ÐµÑÑ‚Ð¾Ð²Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ"""
    print("ðŸŽ² Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ñ‚ÐµÑÑ‚Ð¾Ð²Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…...")
    
    try:
        hook = PostgresHook(postgres_conn_id='analytics_db')
        conn = hook.get_conn()
        cursor = conn.cursor()
        
        # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ñ‚ÐµÑÑ‚Ð¾Ð²Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ
        from datetime import datetime
        test_data = [
            ('test_user_001', 'movie_001', 300, 'start', datetime.now()),
            ('test_user_002', 'movie_002', 450, 'pause', datetime.now()),
            ('test_user_001', 'movie_001', 600, 'stop', datetime.now()),
        ]
        
        for data in test_data:
            cursor.execute("""
                INSERT INTO user_views (user_id, movie_id, duration_seconds, event_type, event_timestamp)
                VALUES (%s, %s, %s, %s, %s)
            """, data)
        
        conn.commit()
        print("âœ… Ð¢ÐµÑÑ‚Ð¾Ð²Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð´Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ñ‹")
        
        cursor.close()
        conn.close()
        
    except Exception as e:
        print(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð´Ð°Ð½Ð½Ñ‹Ñ…: {e}")
        raise

def calculate_simple_metrics():
    """Ð Ð°ÑÑÑ‡Ð¸Ñ‚Ñ‹Ð²Ð°ÐµÑ‚ Ð¿Ñ€Ð¾ÑÑ‚Ñ‹Ðµ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸"""
    print("ðŸ“Š Ð Ð°ÑÑ‡ÐµÑ‚ Ð¼ÐµÑ‚Ñ€Ð¸Ðº...")
    
    try:
        hook = PostgresHook(postgres_conn_id='analytics_db')
        conn = hook.get_conn()
        cursor = conn.cursor()
        
        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñƒ Ð´Ð»Ñ Ð¼ÐµÑ‚Ñ€Ð¸Ðº
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS airflow_metrics (
                id SERIAL PRIMARY KEY,
                metric_name VARCHAR(100),
                metric_value FLOAT,
                calculated_at TIMESTAMP DEFAULT NOW()
            )
        """)
        
        # Ð Ð°ÑÑÑ‡Ð¸Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ Ð±Ð°Ð·Ð¾Ð²Ñ‹Ðµ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸
        cursor.execute("SELECT COUNT(*) FROM user_views")
        total_views = cursor.fetchone()[0]
        
        cursor.execute("SELECT COUNT(DISTINCT user_id) FROM user_views")
        unique_users = cursor.fetchone()[0]
        
        cursor.execute("SELECT AVG(duration_seconds) FROM user_views")
        avg_duration = cursor.fetchone()[0] or 0
        
        # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸
        metrics = [
            ('total_views', total_views),
            ('unique_users', unique_users),
            ('avg_duration', avg_duration)
        ]
        
        for name, value in metrics:
            cursor.execute("""
                INSERT INTO airflow_metrics (metric_name, metric_value)
                VALUES (%s, %s)
            """, (name, value))
        
        conn.commit()
        
        print(f"âœ… ÐœÐµÑ‚Ñ€Ð¸ÐºÐ¸ Ñ€Ð°ÑÑÑ‡Ð¸Ñ‚Ð°Ð½Ñ‹:")
        print(f"   - Ð’ÑÐµÐ³Ð¾ Ð¿Ñ€Ð¾ÑÐ¼Ð¾Ñ‚Ñ€Ð¾Ð²: {total_views}")
        print(f"   - Ð£Ð½Ð¸ÐºÐ°Ð»ÑŒÐ½Ñ‹Ñ… Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÐµÐ¹: {unique_users}")
        print(f"   - Ð¡Ñ€ÐµÐ´Ð½ÑÑ Ð´Ð»Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ: {avg_duration:.2f} ÑÐµÐº")
        
        cursor.close()
        conn.close()
        
    except Exception as e:
        print(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ñ€Ð°ÑÑ‡ÐµÑ‚Ð° Ð¼ÐµÑ‚Ñ€Ð¸Ðº: {e}")
        raise

# Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ DAG
with DAG(
    'movie_analytics_simple',
    default_args=default_args,
    description='ÐŸÑ€Ð¾ÑÑ‚Ð¾Ð¹ DAG Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ñ‚Ð¸ÐºÐ¸ Ñ„Ð¸Ð»ÑŒÐ¼Ð¾Ð²',
    schedule_interval=timedelta(hours=1),
    catchup=False,
    tags=['movie', 'analytics', 'simple']
) as dag:

    check_connection = PythonOperator(
        task_id='check_database_connection',
        python_callable=check_database_connection
    )

    generate_data = PythonOperator(
        task_id='generate_test_data',
        python_callable=generate_test_data
    )

    calculate_metrics = PythonOperator(
        task_id='calculate_simple_metrics',
        python_callable=calculate_simple_metrics
    )

    # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ Ð¿Ð¾Ñ€ÑÐ´Ð¾Ðº Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ñ
    check_connection >> generate_data >> calculate_metrics